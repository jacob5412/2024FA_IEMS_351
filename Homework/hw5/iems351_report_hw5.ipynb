{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a2b471-4021-43c0-ae0e-3bbaf8c0aa74",
   "metadata": {},
   "source": [
    "# IMES 351 HW 5 \n",
    "## Solving logistic regression problems using gradient methods \n",
    "Please put iems351_hw5_ex1.csv, iems351_report_hw5.ipynb, and iems_tools_hw5.py in the same folder. \n",
    "\n",
    "Please do the following to finish HW 5:\n",
    "\n",
    "(1) Finish the implementation of gradient methods in iems_tools_hw5.py \n",
    "\n",
    "Notes: Update rule in the gradient method with diminishing step size rule is \n",
    "$$\n",
    "x^{k+1} = x^k - \\frac{\\alpha}{k+1} \\nabla f(x^k) \\quad k = 0,1,2,\\ldots\n",
    "$$\n",
    "\n",
    "(2) Finish the exercises in iems351_report_hw5.ipynb \n",
    "\n",
    "(3) Save your finished iems351_report_hw5.ipynb with all the outputs as a .HTML file  \n",
    "\n",
    "(4) Submit iems351_tools_hw5.py, iems351_report_hw5.ipynb, and the .HTML file to Canvas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c52229c-7f0f-4f59-a9c1-831ba99de532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from iems351_tools_hw5 import gradient_method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779f4d3-fdb8-44e8-b8ba-cc46563c7b60",
   "metadata": {},
   "source": [
    "## Exercise 1: Finish the implementation of logistic regrsssion models \n",
    "## Logistic regression problem with labels ($+1$ or $-1$) is formulated as follows: \n",
    "$$\n",
    "\\boxed{\\min_{x} \\sum_{i=1}^N \\log \\left(1 + \\exp{(-y^{(i)} \\cdot x^\\top z^{(i)}}) \\right)}\n",
    "$$\n",
    "Requirement 1.1: Please do not use loops to compute objective function value or gradient value. Instead, you should use numpy matrix multiplication directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef30ef4-c35b-462d-8204-57f256c23a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a logistic regression model\n",
    "\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(t):\n",
    "    \"\"\"\n",
    "    :param t: float or a numpy array\n",
    "\n",
    "    :return: float or a numpay array\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "\n",
    "# objective function\n",
    "def logistic_obj(x, Z, y):\n",
    "    \"\"\"\n",
    "    :param x: numpy array (n,)\n",
    "    :param Z: numpy array (N,n)\n",
    "    :param y: numpy array (N,)\n",
    "\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    linear_term = y * (Z @ x)\n",
    "    return np.sum(np.log(1 + np.exp(-linear_term)))  # obj func\n",
    "\n",
    "\n",
    "# gradient function\n",
    "def logistic_grad(x, Z, y):\n",
    "    \"\"\"\n",
    "    :param x: numpy array (n,)  \n",
    "    :param Z: numpy array (N,n)\n",
    "    :param y: numpy array (N,)\n",
    "\n",
    "    :return: numpy array (n,)\n",
    "    \"\"\"\n",
    "    linear_term = y * (Z @ x)\n",
    "    gradient = Z.T @ (-y * sigmoid(-linear_term))\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def logistic_classification_model(x, z, threshold=0.5):\n",
    "    prob = sigmoid(x @ z)\n",
    "    if prob > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def logistic_prob(x, Z):\n",
    "    prob = sigmoid(Z @ x)\n",
    "    return prob\n",
    "\n",
    "\n",
    "def prediction_accuracy(x, Z, y, threshold=0.5):\n",
    "    # sample size\n",
    "    N = len(y)\n",
    "    # count\n",
    "    counter_correct = 0\n",
    "    for i in range(N):\n",
    "        # predict label\n",
    "        prob = sigmoid(x @ Z[i])\n",
    "        if prob > threshold:\n",
    "            predict_label = 1\n",
    "        else:\n",
    "            predict_label = -1\n",
    "        if predict_label * y[i] > 0:  # correct\n",
    "            counter_correct += 1\n",
    "    return counter_correct / N\n",
    "\n",
    "\n",
    "logistic_model = {\n",
    "    \"classification_model\": logistic_classification_model,\n",
    "    \"prob\": logistic_prob,\n",
    "    \"obj\": logistic_obj,\n",
    "    \"grad\": logistic_grad,\n",
    "    \"prediction_accuracy\": prediction_accuracy,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771f1d8-439d-4cf6-be90-0bed9ed6ba1d",
   "metadata": {},
   "source": [
    "## Exercise 2: Run the following toy example\n",
    "Requirement 2.1: You should see that the accuracy of the logistic regression model trained by the gradient methods is above 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04436675-a4ec-413b-af21-1c80f1de63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_file_name = \"iems351_hw5_ex1.csv\"\n",
    "ex1_df = pd.read_csv(ex1_file_name)\n",
    "y_train = ex1_df[\"y\"].to_numpy()\n",
    "Z_train = ex1_df[[\"z1\", \"z2\"]].to_numpy()\n",
    "# Set up algorithmic parameters\n",
    "alg_param_const = {\n",
    "    \"alpha\": 1e-2,\n",
    "    \"freq_print_obj\": 50,\n",
    "    \"freq_print_accuracy\": 100,\n",
    "    \"max_iteration\": 2000,\n",
    "    \"flag_constant_step_size\": True,\n",
    "    \"flag_diminishing_step_size\": False,\n",
    "}\n",
    "\n",
    "alg_param_diminishing = {\n",
    "    \"alpha\": 1,\n",
    "    \"freq_print_obj\": 100,\n",
    "    \"freq_print_accuracy\": 200,\n",
    "    \"max_iteration\": 4000,\n",
    "    \"flag_constant_step_size\": False,\n",
    "    \"flag_diminishing_step_size\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ec805-0899-4f87-be10-87ba2f6d2318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using a gradient method with constant step size\n",
    "x_init = np.zeros(2)\n",
    "x_train = gradient_method(x_init, Z_train, y_train, logistic_model, alg_param_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc519d6-c919-47ee-8e94-139687ef42c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using a gradient method with diminishing step size\n",
    "x_train = gradient_method(x_init, Z_train, y_train, logistic_model, alg_param_diminishing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f6ab25-2fcc-43fd-8a1b-ed8a0f748171",
   "metadata": {},
   "source": [
    "## Exercise 3: Find the proper step size parameter for spam email example \n",
    "Hint: The stepsize must be very small in this example. Otherwise, you may see the objective function value becomes inf. \n",
    "\n",
    "Requirement 3.1: The accuracy of the logistic regression model trained by the gradient method with constant step size rule is above 0.7\n",
    "\n",
    "Requirement 3.2: The accuracy of the logistic regression model trained by the gradient method with diminishing step size rule is above 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974a511-f57a-4919-ab39-1373e073958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "spambase = fetch_ucirepo(id=94)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "Z = spambase.data.features\n",
    "y = spambase.data.targets\n",
    "\n",
    "# metadata\n",
    "# print(spambase.metadata)\n",
    "\n",
    "# variable information\n",
    "# print(spambase.variables)\n",
    "# Convert Z to numpy array\n",
    "N = len(y)\n",
    "Z_np = Z.to_numpy()\n",
    "Z_np = np.concatenate((Z_np, np.ones((N, 1))), axis=1)\n",
    "print(Z_np)\n",
    "# Convert y to numpy array and convert {+1, 0} into {+1, -1}\n",
    "y_np = y.to_numpy() * 2 - 1\n",
    "y_np = np.squeeze(y_np)\n",
    "print(y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ffd2e8-8366-40ba-b7ee-ff9f8bc445d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up algorithmic parameters\n",
    "# ======================================================================================\n",
    "# Write your choice of step size\n",
    "alg_param_const = {\n",
    "    \"alpha\": 1e-8,  # very small step size\n",
    "    \"freq_print_obj\": 100,\n",
    "    \"freq_print_accuracy\": 200,\n",
    "    \"max_iteration\": 1001,\n",
    "    \"flag_constant_step_size\": True,\n",
    "    \"flag_diminishing_step_size\": False,\n",
    "}\n",
    "\n",
    "alg_param_diminishing = {\n",
    "    \"alpha\": 1e-5,  # larger initial step size for diminishing\n",
    "    \"freq_print_obj\": 100,\n",
    "    \"freq_print_accuracy\": 200,\n",
    "    \"max_iteration\": 5001,\n",
    "    \"flag_constant_step_size\": False,\n",
    "    \"flag_diminishing_step_size\": True,\n",
    "}\n",
    "# ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db338b-d957-48b3-82bd-5a817d9d1483",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = np.ones(58) * 0.001\n",
    "x = gradient_method(x_init, Z_np, y_np, logistic_model, alg_param_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d49579-27bf-4126-aa14-310d6f0e2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gradient_method(x_init, Z_np, y_np, logistic_model, alg_param_diminishing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb4da83-346a-4e89-bfd0-e50492cf792a",
   "metadata": {},
   "source": [
    "## Exercise 4: Data normalization \n",
    "Here, we normalize the data by its mean. \n",
    "\n",
    "Requirement 4.1: The accuracy of the logistic regression model trained by the gradient method with constant step size rule is above 0.9\n",
    "\n",
    "Requirement 4.2: The accuracy of the logistic regression model trained by the gradient method with diminishing step size rule is above 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd31fcf-e092-4577-8fbb-87bce8dd1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "scaling_factor = np.mean(Z_np, axis=0)\n",
    "print(scaling_factor)\n",
    "Z_scale = Z_np / scaling_factor\n",
    "print(Z_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede72b64-2e8d-4913-af2e-c0bcc63ec441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up algorithmic parameters\n",
    "# ======================================================================================\n",
    "# Write your choice of step size\n",
    "alg_param_const = {\n",
    "    \"alpha\": 1e-4,\n",
    "    \"freq_print_obj\": 100,\n",
    "    \"freq_print_accuracy\": 200,\n",
    "    \"max_iteration\": 1001,\n",
    "    \"flag_constant_step_size\": True,\n",
    "    \"flag_diminishing_step_size\": False,\n",
    "}\n",
    "\n",
    "alg_param_diminishing = {\n",
    "    \"alpha\": 1e-3,\n",
    "    \"freq_print_obj\": 100,\n",
    "    \"freq_print_accuracy\": 200,\n",
    "    \"max_iteration\": 1001,\n",
    "    \"flag_constant_step_size\": False,\n",
    "    \"flag_diminishing_step_size\": True,\n",
    "}\n",
    "# ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9fe0a-bead-4653-ba8e-bf7848f4df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = np.ones(58) * 0.001\n",
    "x = gradient_method(x_init, Z_scale, y_np, logistic_model, alg_param_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1652420-b347-401c-a343-0d45e021af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gradient_method(x_init, Z_scale, y_np, logistic_model, alg_param_diminishing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be7e34-092e-41bd-8ddf-58ddd37cf9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
