{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc7d066-3a5f-44a1-a445-22db90488f4f",
   "metadata": {},
   "source": [
    "# IEMS 351 Lab 3 Fall 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07169270-0947-48a2-851a-7d182a7bbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import FancyArrowPatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f95d8-9c6d-43ff-8866-2f7a07949eca",
   "metadata": {},
   "source": [
    "# Unconstrained Minimization Problem \n",
    "$$\n",
    "\\min_{x \\in \\mathbb{R}^n} f(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1be92-3d47-45ce-b1dc-94e9ee223f9d",
   "metadata": {},
   "source": [
    "## Update rule with constant step size in the gradient method \n",
    "\n",
    "$$\n",
    "x_{k+1} = x_k - \\alpha \\nabla f(x_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cbacb7-b09c-42e5-b4a5-1a14abd7f283",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "$$\n",
    "\\min_{x \\in \\mathbb{R}^2} \\ f(x_1, x_2) = x_1^2 + x_2^2\n",
    "$$\n",
    "Gradient of $f$ is \n",
    "$$\n",
    "\\nabla f(x) = \\begin{bmatrix}\n",
    "2 x_1 \\\\\n",
    "2 x_2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Hessian of $f$ is \n",
    "$$\n",
    "\\nabla^2 f(x) = \\begin{bmatrix}\n",
    "2 & 0\\\\\n",
    "0 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1141bb-25e9-4c45-a2ae-538b79c7234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters in the gradient method\n",
    "def func1(x):\n",
    "    return x[0] * x[0] + x[1] * x[1]\n",
    "\n",
    "\n",
    "def grad_func1(x):\n",
    "    return np.array([2 * x[0], 2 * x[1]])\n",
    "\n",
    "\n",
    "# stepsize\n",
    "alpha = 0.2\n",
    "# initial point\n",
    "x0 = np.array([4, -4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a1a28-9864-4a44-a868-ea15c4d0849e",
   "metadata": {},
   "source": [
    "## Generate a contour plot of example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c4585-a628-4516-a369-a1906bb68535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the contour\n",
    "x = np.linspace(-6, 6, 50)\n",
    "y = np.linspace(-6, 6, 50)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = X * X + Y * Y\n",
    "CS = plt.contour(X, Y, Z, 10, cmap=\"jet\", linewidths=2)\n",
    "plt.clabel(CS, inline=1, fontsize=10)\n",
    "# plot the initial point\n",
    "plt.plot(x0[0], x0[1], \"or\", markersize=4)\n",
    "plt.text(x0[0] + 0.1, x0[1] + 0.1, \"initial point\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87ba6f9-79c9-4da4-acc1-9702e5509993",
   "metadata": {},
   "source": [
    "## Plot the trajectory of gradient method in the first iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed6c57-2e5d-450c-a526-568f5ae77eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first iteration\n",
    "grad_x0 = grad_func1(x0)\n",
    "x1 = x0 - alpha * grad_x0\n",
    "# plot arrow\n",
    "arrow = FancyArrowPatch(\n",
    "    (x0[0], x0[1]), (x1[0], x1[1]), arrowstyle=\"simple\", color=\"k\", mutation_scale=10\n",
    ")\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "CS = ax.contour(X, Y, Z, 10, cmap=\"jet\", linewidths=2)\n",
    "ax.clabel(CS, inline=1, fontsize=10)\n",
    "ax.add_patch(arrow)\n",
    "# plot the initial point\n",
    "ax.plot(x0[0], x0[1], \"or\", markersize=4)\n",
    "ax.plot(x1[0], x1[1], \"or\", markersize=4)\n",
    "ax.text(x0[0] + 0.1, x0[1] + 0.1, r\"$x^0$\")\n",
    "ax.text(x1[0] + 0.1, x1[1] + 0.1, r\"$x^1$\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"Iteration 1\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbc9b9-12b0-461f-934d-aad3aa83cfaa",
   "metadata": {},
   "source": [
    "## Plot the trajectory of gradient method in the second iteration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981095bc-6aae-4b47-9d76-4100e227a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second iteration\n",
    "grad_x1 = grad_func1(x1)\n",
    "x2 = x1 - alpha * grad_x1\n",
    "# plot arrow\n",
    "arrow1 = FancyArrowPatch(\n",
    "    (x0[0], x0[1]), (x1[0], x1[1]), arrowstyle=\"simple\", color=\"k\", mutation_scale=10\n",
    ")\n",
    "arrow2 = FancyArrowPatch(\n",
    "    (x1[0], x1[1]), (x2[0], x2[1]), arrowstyle=\"simple\", color=\"k\", mutation_scale=10\n",
    ")\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "CS = ax.contour(X, Y, Z, 10, cmap=\"jet\", linewidths=2)\n",
    "ax.clabel(CS, inline=1, fontsize=10)\n",
    "ax.add_patch(arrow1)\n",
    "ax.add_patch(arrow2)\n",
    "# plot the initial point\n",
    "ax.plot(x0[0], x0[1], \"or\", markersize=4)\n",
    "ax.plot(x1[0], x1[1], \"or\", markersize=4)\n",
    "ax.plot(x2[0], x2[1], \"or\", markersize=4)\n",
    "ax.text(x0[0] + 0.1, x0[1] + 0.1, r\"$x^0$\")\n",
    "ax.text(x1[0] + 0.1, x1[1] + 0.1, r\"$x^1$\")\n",
    "ax.text(x2[0] + 0.1, x2[1] + 0.1, r\"$x^2$\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"Iteration 2\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2909fc60-05b6-4699-8cb1-8bcaaed3b5eb",
   "metadata": {},
   "source": [
    "## Plot the entire trajectory of the gradient method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d47c0-3b8d-4870-967b-e9fb007903c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let us plot the progress of gradient method iteratively\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "CS = ax.contour(X, Y, Z, 10, cmap=\"jet\", linewidths=2)\n",
    "ax.clabel(CS, inline=1, fontsize=10)\n",
    "\n",
    "# max number of iterations\n",
    "max_iterations = 5\n",
    "# initialize current x\n",
    "cur_x = x0\n",
    "ax.text(cur_x[0] + 0.1, cur_x[1] + 0.1, r\"$x^0$\")\n",
    "ax.plot(cur_x[0], cur_x[1], \"or\", markersize=4)\n",
    "for i in range(max_iterations):\n",
    "    cur_grad = grad_func1(cur_x)\n",
    "    next_x = cur_x - alpha * cur_grad\n",
    "    arrow = FancyArrowPatch(\n",
    "        (cur_x[0], cur_x[1]),\n",
    "        (next_x[0], next_x[1]),\n",
    "        arrowstyle=\"simple\",\n",
    "        color=\"k\",\n",
    "        mutation_scale=5,\n",
    "    )\n",
    "    ax.add_patch(arrow)\n",
    "    ax.plot(next_x[0], next_x[1], \"or\", markersize=4)\n",
    "    ax.text(next_x[0] + 0.1, next_x[1] + 0.1, r\"$x^{}$\".format(i + 1))\n",
    "    # update\n",
    "    cur_x = next_x\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee440c53-1dd1-4627-a3e5-b4a7041933e6",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "$$\n",
    "\\min_{x \\in \\mathbb{R}^2} \\ f(x_1,x_2) = x_1^2 \\sin(x_2) + x_2 \\cos(x_1) \n",
    "$$\n",
    "The gradient of $f$ is \n",
    "$$\n",
    "\\nabla f(x) = \\begin{bmatrix}\n",
    "            2 x_1 \\sin x_2 - x_2 \\sin x_1 \\\\\n",
    "            x_1^2 \\cos x_2 + \\cos x_1\n",
    "        \\end{bmatrix}\n",
    "$$\n",
    "The Hessian of $f$ is \n",
    "$$\n",
    "\\textbf{H} f(x) = \\begin{bmatrix}\n",
    "        2\\sin x_2 - x_2 \\cos x_1 & 2 x_1 \\cos x_2 - \\sin x_1 \\\\\n",
    "        2 x_1 \\cos x_2 - \\sin x_1 & -x_1^2 \\sin x_2\n",
    "        \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e051eb20-f745-4ef5-885c-2b6cb159e725",
   "metadata": {},
   "source": [
    "## TODO1: Plot the trajectory of the gradient method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81b5e2-5ed6-488f-a879-034567bcf1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters in the gradient method\n",
    "def func2(x):\n",
    "    return (x[0] ** 2 * np.sin(x[0])) + (x[1] * np.cos(x[1]))\n",
    "\n",
    "\n",
    "def grad_func2(x):\n",
    "    return np.array(\n",
    "        [\n",
    "            (2 * x[0] * np.sin(x[1])) - (x[1] * np.sin(x[0])),\n",
    "            ((x[0] ** 2) * np.cos(x[1])) + (np.cos(x[0])),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# stepsize\n",
    "alpha = 0.2\n",
    "# initial point\n",
    "x0 = np.array([4, -4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fa37e-165f-40a9-88a6-6be1983bcc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let us plot the progress of gradient method\n",
    "x = np.arange(2, 15, 0.1)\n",
    "y = np.arange(-5, 20, 0.1)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = X * X * np.sin(Y) + Y * np.cos(X)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "CS = ax.contour(X, Y, Z, 10, cmap=\"jet\", linewidths=2)\n",
    "ax.clabel(CS, inline=1, fontsize=10)\n",
    "\n",
    "# max number of iterations\n",
    "max_iterations = 8\n",
    "# reset the stepszie alpha\n",
    "alpha = 0.1\n",
    "# initialize current x\n",
    "cur_x = x0\n",
    "ax.text(cur_x[0] + 0.1, cur_x[1] + 0.1, r\"$x^0$\")\n",
    "ax.plot(cur_x[0], cur_x[1], \"or\", markersize=4)\n",
    "for i in range(max_iterations):\n",
    "    cur_grad = grad_func2(cur_x)\n",
    "    next_x = cur_x - alpha * cur_grad\n",
    "    arrow = FancyArrowPatch(\n",
    "        (cur_x[0], cur_x[1]),\n",
    "        (next_x[0], next_x[1]),\n",
    "        arrowstyle=\"simple\",\n",
    "        color=\"k\",\n",
    "        mutation_scale=5,\n",
    "    )\n",
    "    ax.add_patch(arrow)\n",
    "    ax.plot(next_x[0], next_x[1], \"or\", markersize=4)\n",
    "    ax.text(next_x[0] + 0.1, next_x[1] + 0.1, r\"$x^{}$\".format(i + 1))\n",
    "    # update\n",
    "    cur_x = next_x\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd19e33a-8d34-47b5-ab6c-b722ae0308db",
   "metadata": {},
   "source": [
    "## TODO2: Make the stepszie $\\alpha$ smaller and plot the trajectory of the gradient method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3600c-db14-445b-b922-286f78a76030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let us plot the progress of gradient method\n",
    "x = np.arange(2, 15, 0.1)\n",
    "y = np.arange(-5, 20, 0.1)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = X * X * np.sin(Y) + Y * np.cos(X)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "CS = ax.contour(X, Y, Z, 10, cmap=\"jet\", linewidths=2)\n",
    "ax.clabel(CS, inline=1, fontsize=10)\n",
    "\n",
    "# max number of iterations\n",
    "max_iterations = 100\n",
    "# reset the stepszie alpha\n",
    "alpha = 0.5\n",
    "# initialize current x\n",
    "cur_x = x0\n",
    "ax.text(cur_x[0] + 0.1, cur_x[1] + 0.1, r\"$x^0$\")\n",
    "ax.plot(cur_x[0], cur_x[1], \"or\", markersize=4)\n",
    "for i in range(max_iterations):\n",
    "    cur_grad = grad_func2(cur_x)\n",
    "    next_x = cur_x - alpha * cur_grad/(1+i)\n",
    "    arrow = FancyArrowPatch(\n",
    "        (cur_x[0], cur_x[1]),\n",
    "        (next_x[0], next_x[1]),\n",
    "        arrowstyle=\"simple\",\n",
    "        color=\"k\",\n",
    "        mutation_scale=5,\n",
    "    )\n",
    "    ax.add_patch(arrow)\n",
    "    ax.plot(next_x[0], next_x[1], \"or\", markersize=4)\n",
    "    ax.text(next_x[0] + 0.1, next_x[1] + 0.1, r\"$x^{}$\".format(i + 1))\n",
    "    # update\n",
    "    cur_x = next_x\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ef9fc-924a-43fe-ae4c-605dc804500c",
   "metadata": {},
   "source": [
    "## Question: Does the global minimier of $f(x_1,x_2) = x_1^2 \\sin(x_2) + x_2 \\cos(x_1)$ exist?\n",
    "Hint: Set $x_2 = \\frac{3\\pi}{2}$ and let $x_1 \\rightarrow \\infty$, what do you obersve? \n",
    "\n",
    "$$\n",
    "x_1^2 \\sin(x_2) + x_2 \\cos(x_1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Leftrightarrow \\infty \\sin(\\frac{3\\pi}{2}) + \\frac{3\\pi}{2} \\cos(\\infty)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Leftrightarrow - \\infty + \\frac{3\\pi}{2} \\cos(\\infty)\n",
    "$$\n",
    "\n",
    "The first part of the equation is unbounded, which means there isn't a way to figure out a globally min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4cf61-3429-4e1a-bccb-4cd76707efaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
